{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Krystian_FIgiel_projekt_kodeks_karny.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-Bambi/LSTM-text-generator/blob/master/Krystian_FIgiel_projekt_kodeks_karny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2NyDdfmu-53",
        "colab_type": "text"
      },
      "source": [
        "#Krystian Figiel - generowanie tekstu z kodeksu karnego"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IyiOOpuvAxH",
        "colab_type": "code",
        "outputId": "a62a3620-5d0b-4a7a-a4f6-f9c9647b4fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import *\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow import nn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yeYjr7XpMob",
        "colab_type": "text"
      },
      "source": [
        "# Przygotowywanie zestawu danych\n",
        "- usuwanie niepotrzebnych znaków, \n",
        "- usuwanie dat\n",
        "- zastępowanie polskich znaków\n",
        "\n",
        "w celu zmniejszenia wektora znaków do generowania - wielkość tego wektora bardzo wpływa na czas i skuteczność uczenia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsQfAIWJXR8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('kodeks.txt','r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORn4G14qUHUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear(line):\n",
        "  i = line.find('©')\n",
        "  if i >= 0:\n",
        "    return \"\"\n",
        "  j = line.find('s. ')\n",
        "  if j >= 0:\n",
        "    return \"\"\n",
        "  cleared = line.replace('\\n',' ').replace('§','').lower().replace('ł','l').replace('ą','a').replace('ę','e').replace('ż','z').replace('ź','z').replace('ń','n').replace('ó','o').replace('ś','s').replace('ć','c').replace(\"\\x0c\",\"\").replace(\"”\",chr(34)).replace(\"„\",chr(34)).replace(\"–\",\"-\")\n",
        "  return cleared"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG_vQeReT_R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "everything = ''\n",
        "\n",
        "for line in file:\n",
        "  everything += clear(line)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR08BRG5r8cI",
        "colab_type": "text"
      },
      "source": [
        "Regular Expressions jako łatwy sposób na usuwanie konkretnych ciągów znaków - w tym przypadku dat i powtarzających się spacji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjhODQCYVXwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "everything = re.sub(' +', ' ', everything)\n",
        "everything = re.sub('^(?:(?:[0-9]{2}[:\\/,]){2}[0-9]{2,4}|am|pm)$', '', everything)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Zx_V4DVeKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signs_set = set(everything)\n",
        "signs_to_ints = {}\n",
        "ints_to_signs = {}\n",
        "for i,s in enumerate(sorted(signs_set)):\n",
        "  ints_to_signs[i], signs_to_ints[s] = s, i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEbLPJngwNeF",
        "colab_type": "text"
      },
      "source": [
        "Słowniki *ints_to_signs* i *signs_to_ints* służą do wektoryzacji liter i do odkodowania wektorów liter. Każdemu znakowi przypisuje się numer, który potem służy do stworzenia tablicy numpy wypełnionej zerami i 1 na odpowiednim indeksie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRc7aud9Zast",
        "colab_type": "code",
        "outputId": "310cb6ca-3ef8-488a-a1e4-6a5855ff4054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(everything), len(signs_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(248985, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82QXFBvLpxrq",
        "colab_type": "text"
      },
      "source": [
        "Ostateczna długość całego tekstu to 248985 znaków ze zbioru 46 unikatowych.\n",
        "\n",
        "Następny segment to podział znaków na zbiór uczący i etykiety. LSTM na wejściu bierze wektor 3D. W celu utworzenia takiego zbioru należy podzielić cały tekst na odcinki po N liter, i każdemu takiemu odcinkowi przypisać etykietę w postaci kolejnej litery, która występuję w tekście po tym ciągu znaków. Sieć nauczy się generować literę na podstawie ciągu znaków."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8nF516sZhCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 40\n",
        "step = 1\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(120000, len(everything) - maxlen, step):\n",
        "    sentences.append(everything[i: i + maxlen])\n",
        "    next_chars.append(everything[i + maxlen])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9tWvgq9wr_m",
        "colab_type": "text"
      },
      "source": [
        "#Wektoryzacja liter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9LAfOlMZi1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(signs_set)))\n",
        "y = np.zeros((len(sentences), len(signs_set)))\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, signs_to_ints[char]] = 1\n",
        "    y[i, signs_to_ints[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exIW0JgCvtze",
        "colab_type": "text"
      },
      "source": [
        "Zbiór X to trójwymiarowa tablica numpy. W tym przypadku ma wymiary (128935, 40, 46), czyli 128935 \"zdań\" po 40 znaków, gdzie każdy znak jest przedstawiony wektorowo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0MP-Ikzq82V",
        "colab_type": "text"
      },
      "source": [
        "# Budowa modelu.\n",
        "Użyłem warstwy CuDNNLSTM, czyli implementacji LSTM w technologii CUDA, która została napisana specjalnie do obliczeń na kartach graficznych. Przyspiesza to uczenie sieci ~10-krotnie. Na wyjściu musi się znaleźć warstwa w pełni połączona o wielkości odpowiadającej długości zbioru unikatowych znaków. Metodą prób i błędów odkryłem, że sieć uczy się bardzo skutecznie po połączeniu warstwy LSTM i wyjściowej jeszcze jedną warstwą w pełni połączoną."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbkK81VjbFeC",
        "colab_type": "code",
        "outputId": "e697ff45-ff1f-4853-e908-9f83dd0c1710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(CuDNNLSTM(128, input_shape=(maxlen, len(signs_set)), return_sequences=False))\n",
        "model.add(Dense(128))\n",
        "model.add(Dense(len(signs_set), activation=nn.softmax))\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IMJLf8osMBs",
        "colab_type": "text"
      },
      "source": [
        "# Uczenie modelu\n",
        "W tym przypadku model potrzebuje stosunkowo dużej ilości epok, a zjawisko przeuczenia (widoczne jako rosnąca strata zbioru walidacyjnego) nie jest niemile widziane - w pewnym sensie model powinien się nauczyć \"na pamięć\". Po więcej niż ~50 epokach strata zaczyna rosnąć."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTAOr9lxbJuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = 0\n",
        "b = 120\n",
        "model.fit(x[a*1000:b*1000], y[a*1000:b*1000], batch_size=128, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOymPi89s4_O",
        "colab_type": "text"
      },
      "source": [
        "Generowanie tekstu rozpoczyna się od wrzucenie do sieci \"seed\", czyli początkowego fragmentu tekstu, który będzie podstawą dla sieci do wygenerowania kolejnej litery. Następnie wygenerowana litera jest dodana do końca zdania, z którego również ucina się pierwszą literę. Taką czynność powtarza się tyle razy ile chcemy, żeby sieć wygenerowała tekstu. Od pewnego momentu sieć działa wyłącznie na wygenerowanym przez siebie tekście."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KBg_UtX393l",
        "colab_type": "code",
        "outputId": "a5555d61-36e5-43cb-c69c-eef233aafe99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "start_index = randint(0, len(everything) - maxlen - 1)\n",
        "sentence = everything[start_index: start_index + maxlen]\n",
        "\n",
        "generated = ''\n",
        "generated += \"[{}]\".format(sentence)\n",
        "file = open(\"generated.txt\",\"a\")\n",
        "\n",
        "for i in range(500):\n",
        "    x_pred = np.zeros((1, maxlen, len(signs_set)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, signs_to_ints[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)\n",
        "    next_index = np.argmax(preds)\n",
        "    next_char = ints_to_signs[next_index]\n",
        "\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "    \n",
        "generated += '\\n'\n",
        "print(generated)\n",
        "file.write(generated)\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[k na zdrowiu czlowieka, sprawca podlega ]karze pozbawienia wolnosci od 3 miesiecy do lat 5. art. 277bia 16 lu art. 271a 1 lub 2 albo art. 277c art. 233 skazania czynnosci wymagajacych z handlem osobe na podstawie wyroku trybunalu konstytucyjnego zamach albo istotnie lub informacji lub taka jako taki albo doprowadzajac czlowieka do stanu nieprawnien orzeczenia sadu lub innym powinienie lub uszkadzajac czynu zabronionego okreslonego w art. 233 i 2000 srost albo o glosowanie w okreslony sposob moze to dzialajacej w wysokosci do samodziele\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6DNsdmj5iS3",
        "colab_type": "text"
      },
      "source": [
        "#Generowanie z temperaturą\n",
        "\n",
        "Wygenerowaną tablicę można zmienić, dzięki czemu uzyskuje się bardziej zróżnicowane wyniki, co prowadzi też do bardziej zróżnicowanych przewidywań.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyPSPKnZ5irC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcUeIO6ub_rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in range(20):\n",
        "  start_index = randint(0, len(everything) - maxlen - 1)\n",
        "\n",
        "  file = open(\"generated.txt\",\"a\")\n",
        "\n",
        "  for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "      generated = ''\n",
        "      sentence = everything[start_index: start_index + maxlen]\n",
        "      generated += \"[{}]\".format(sentence)\n",
        "\n",
        "      for i in range(500):\n",
        "          x_pred = np.zeros((1, maxlen, len(signs_set)))\n",
        "          for t, char in enumerate(sentence):\n",
        "              x_pred[0, t, signs_to_ints[char]] = 1.\n",
        "\n",
        "          preds = model.predict(x_pred, verbose=0)[0]\n",
        "          next_index = sample(preds, diversity)\n",
        "          next_char = ints_to_signs[next_index]\n",
        "\n",
        "          sentence = sentence[1:] + next_char\n",
        "          generated += next_char\n",
        "\n",
        "  generated += '\\n'\n",
        "  print(generated)\n",
        "  file.write(generated)\n",
        "  file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oivwiVWMvS7m",
        "colab_type": "text"
      },
      "source": [
        "#Bibliografia\n",
        "Keras examples directory - https://github.com/keras-team/keras/tree/master/examples [10.06.2019]"
      ]
    }
  ]
}